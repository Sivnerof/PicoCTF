# Scavenger Hunt

## Description

There is some interesting information hidden around this site http://mercury.picoctf.net:5080/. Can you find it?

## Hints

* You should have enough hints to find the files, don't run a brute forcer.

## Walkthrough

Starting off by viewing the source code for the webpage at http://mercury.picoctf.net:5080/, we'll see the following HTML.

```html
<!doctype html>
<html>
  <head>
    <!--...REMOVED FOR BREVITY...-->
    <link rel="stylesheet" type="text/css" href="mycss.css">
    <script type="application/javascript" src="myjs.js"></script>
  </head>
  <body>
    <!--...REMOVED FOR BREVITY...-->
	<!-- Here's the first part of the flag: picoCTF{t -->
    <!--...REMOVED FOR BREVITY...-->
  </body>
</html>
```

The HTML contains a piece of the flag hidden within a comment that reads "Here's the first part of the flag: picoCTF{t", the HTML also links to a CSS file and a JavaScript file. Since we're just starting out and don't have much to go on, we might as well check the contents of these other files as well.

Navigating to the CSS file at http://mercury.picoctf.net:5080/mycss.css we'll see the following source code.

```css
div.container {
    width: 100%;
}

header {
    background-color: black;
    padding: 1em;
    color: white;
    clear: left;
    text-align: center;
}

/*...REMOVED FOR BREVITY...*/

/* CSS makes the page look nice, and yes, it also has part of the flag. Here's part 2: h4ts_4_l0 */
```

It's here within the CSS file, in a comment, that we'll find the second piece of the flag which reads:

> CSS makes the page look nice, and yes, it also has part of the flag. Here's part 2: h4ts_4_l0

Now we can make our way to the JavaScript file at http://mercury.picoctf.net:5080/myjs.js where we'll see the following code.

```js
function openTab(tabName,elmnt,color) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
	tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablink");
    for (i = 0; i < tablinks.length; i++) {
	tablinks[i].style.backgroundColor = "";
    }
    document.getElementById(tabName).style.display = "block";
    if(elmnt.style != null) {
	elmnt.style.backgroundColor = color;
    }
}

window.onload = function() {
    openTab('tabintro', this, '#222');
}

/* How can I keep Google from indexing my website? */
```

Inside the JavaScript file, hidden within a comment, we'll see text that asks us [how the developer can keep Google from indexing their website](https://developers.google.com/search/docs/crawling-indexing/block-indexing "Google Developer article on blocking indexing via meta tag").

There are two ways to stop Google from indexing, one is to add a [meta tag](https://www.w3schools.com/tags/tag_meta.asp "W3 Schools article on meta tags") to the HTML file within the ```<head>``` element like so:

```html
<!--Tells ALL bots not to index-->
<meta name="robots" content="noindex, nofollow">
```

Or:

```html
<!--Tells only the Google bot not to index-->
<meta name="googlebot" content="noindex">
```

Keep in mind that a rogue bot can still crawl your site, since it's ultimately up to the bot developer if they choose to comply with your request to not be indexed.

The [other way to stop Google from indexing your site](https://developers.google.com/search/docs/crawling-indexing/robots/intro "Google Developer article on blocking indexing via ROBOTS text file") is via the [robots.txt file](https://en.wikipedia.org/wiki/Robots.txt "Wikipedia article on robots.txt file").

For example, if you wished to stop ALL bots from indexing your ENTIRE site, you would create a file named "robots.txt" and store it at the root of your site directory (https://example.com/robots.txt) and place the following text inside.

```
User-agent: *
Disallow: /
```

Here, the "*" symbol represents all user agents (bots) and the "/" represents the root directory of your site.

If you wished to ONLY block Google from indexing a folder called "example" you would instead use the following text.

```
User-agent: Googlebot
Disallow: /example
```

Now that we understand how the robots.txt file works, it's important to understand why it is such an important first stop in vulnerability hunting. Naturally, a file that contains directory names that a developer would not like to be indexed is going to attract a lot of attention. Security researchers, bad actors, vulnerability hunters and bad bots can use the "robots.txt" to get an idea of a sites hidden directories as part of the recoinnaissance phase.

http://mercury.picoctf.net:5080/robots.txt



```
User-agent: *
Disallow: /index.html
# Part 3: t_0f_pl4c
# I think this is an apache server... can you Access the next flag?
```

http://mercury.picoctf.net:5080/.htaccess

```
# Part 4: 3s_2_lO0k
# I love making websites on my Mac, I can Store a lot of information there.
```

http://mercury.picoctf.net:5080/.DS_Store

```
Congrats! You completed the scavenger hunt. Part 5: _35844447}
```
